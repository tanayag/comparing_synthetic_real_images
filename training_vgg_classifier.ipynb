{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, transforms, datasets\n",
    "import os\n",
    "import torch.utils.data as utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier = nn.Sequential(nn.Linear(25088,4096),\n",
    "                              nn.ReLU(True),\n",
    "                              nn.Linear(4096, 256),\n",
    "                              nn.ReLU(True),\n",
    "                              nn.Linear(256,1),\n",
    "                              nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "        \n",
    "    image_dataset = datasets.ImageFolder(os.path.join(\"./cvidea/classification_dataset/\"),data_transforms)\n",
    "\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(image_dataset,\n",
    "                                                batch_size=8,shuffle=True)\n",
    "\n",
    "    dataset_size = len(image_dataset)\n",
    "    class_names = image_dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    return dataloader, dataset_size, class_names, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, dataset_size, class_names, num_classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(vgg.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.071\n",
      "[1,    11] loss: 0.651\n",
      "[1,    21] loss: 0.523\n",
      "[1,    31] loss: 0.222\n",
      "[1,    41] loss: 0.017\n",
      "[1,    51] loss: 0.001\n",
      "[1,    61] loss: 0.003\n",
      "[1,    71] loss: 1.063\n",
      "[1,    81] loss: 0.562\n",
      "[1,    91] loss: 0.548\n",
      "[1,   101] loss: 0.441\n",
      "[1,   111] loss: 0.192\n",
      "[1,   121] loss: 0.028\n",
      "[1,   131] loss: 0.001\n",
      "[1,   141] loss: 0.149\n",
      "[1,   151] loss: 0.030\n",
      "[1,   161] loss: 0.032\n",
      "[1,   171] loss: 0.009\n",
      "[1,   181] loss: 0.059\n",
      "[1,   191] loss: 0.065\n",
      "[1,   201] loss: 0.068\n",
      "[1,   211] loss: 0.028\n",
      "[1,   221] loss: 0.007\n",
      "[1,   231] loss: 0.055\n",
      "[1,   241] loss: 0.008\n",
      "[1,   251] loss: 0.003\n",
      "[1,   261] loss: 0.035\n",
      "[1,   271] loss: 0.019\n",
      "[1,   281] loss: 0.016\n",
      "[1,   291] loss: 0.002\n",
      "[1,   301] loss: 0.004\n",
      "[1,   311] loss: 0.008\n",
      "[1,   321] loss: 0.001\n",
      "[1,   331] loss: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greatskull/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.000\n",
      "[2,    11] loss: 0.006\n",
      "[2,    21] loss: 0.000\n",
      "[2,    31] loss: 0.000\n",
      "[2,    41] loss: 0.001\n",
      "[2,    51] loss: 0.000\n",
      "[2,    61] loss: 0.004\n",
      "[2,    71] loss: 0.030\n",
      "[2,    81] loss: 0.008\n",
      "[2,    91] loss: 0.008\n",
      "[2,   101] loss: 0.001\n",
      "[2,   111] loss: 0.001\n",
      "[2,   121] loss: 0.006\n",
      "[2,   131] loss: 0.001\n",
      "[2,   141] loss: 0.001\n",
      "[2,   151] loss: 0.000\n",
      "[2,   161] loss: 0.000\n",
      "[2,   171] loss: 0.000\n",
      "[2,   181] loss: 0.001\n",
      "[2,   191] loss: 0.000\n",
      "[2,   201] loss: 0.000\n",
      "[2,   211] loss: 0.000\n",
      "[2,   221] loss: 0.000\n",
      "[2,   231] loss: 0.000\n",
      "[2,   241] loss: 0.000\n",
      "[2,   251] loss: 0.000\n",
      "[2,   261] loss: 0.000\n",
      "[2,   271] loss: 0.000\n",
      "[2,   281] loss: 0.000\n",
      "[2,   291] loss: 0.000\n",
      "[2,   301] loss: 0.000\n",
      "[2,   311] loss: 0.000\n",
      "[2,   321] loss: 0.000\n",
      "[2,   331] loss: 0.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c4fa71147533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                  (epoch + 1, i + 1, running_loss / 10.0))\n\u001b[1;32m     18\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./vgg_classifier.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 10.0))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg.state_dict(), './vgg_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
